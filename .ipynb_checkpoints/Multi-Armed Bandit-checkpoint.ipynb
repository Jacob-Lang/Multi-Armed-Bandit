{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Armed Bandit\n",
    "\n",
    "A one-armed bandit is a machine in a casino with a lever arm that is pulled. The machine will return a reward with some pre-programmed probability.  \n",
    "<img src=\"one_armed_bandit.jpg\" alt=\"one_armed_bandit\" style=\"height: 200px;\"/>  \n",
    "\n",
    "When there are more than one bandit machines we call this a **multi-armed bandit**. We know that some of the arms have a higher probability of giving a reward and we would like to pull these arms the most often. But to determine which arm returns the best odds we first need to try all the arms out a number of times. This demonstrates the exploitation-exploration trade-off often encountered in reinforcement learning scenarios. The problem can also be mapped to many real world situations (e.g. deciding which is the best restaurant in your local area) so it interesting to look at some solutions to this problem.   \n",
    "<img src=\"multi_armed_bandit.jpg\" alt=\"multi_armed_bandit\" style=\"height: 200px;\"/>\n",
    "\n",
    "\n",
    "Here I simulate a multi-armed bandit (MAB) and some agents to play the MAB with different strategies. Each arm in my MAB returns a reward +1 with a probability $p_{success}$ and zero reward with a probability $1-p_{successs}$. The $p_{success}$ for each arm is randomly decided each time the MAB is simulated and the agents do not know the underlying $p_{success}$ values.\n",
    "\n",
    "First I will create a MAB class and classes for each of the different strategy agents.\n",
    "\n",
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.offsetbox import AnchoredText\n",
    "import numpy as np\n",
    "from scipy.stats import beta\n",
    "from scipy.optimize import root\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "import functools \n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The MAB and agent classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The environemnt\n",
    "class MABEnv():\n",
    "    \"\"\"Multi-Armed Bandit class. Builds a MAB with n_arms arms.\"\"\"\n",
    "    def __init__(self, n_arms=5):\n",
    "        # build MAB with n_arms\n",
    "        self.n_arms = n_arms\n",
    "        self.reset()\n",
    "        # output for render function\n",
    "        self.output = widgets.Output()\n",
    "        display(self.output)\n",
    "\n",
    "                     \n",
    "    def reset(self):\n",
    "        # set probability of success for each arm. even spread\n",
    "        dp = 1/(self.n_arms+1)\n",
    "        self.p_success = dp*np.arange(1, self.n_arms+1)\n",
    "        np.random.shuffle(self.p_success)\n",
    "        self.p_max = max(self.p_success)\n",
    "        self.arg_min = np.argmax(-self.p_success)\n",
    "        \n",
    "        ## store info\n",
    "        # arm successes\n",
    "        self.reward_history = [[0, 0] for _ in range(self.n_arms)]   # [n,k] = [number of trials, number of successes]\n",
    "        # turn by turn rewards\n",
    "        self.rewards = []\n",
    "        # expected regret due to particular strategy\n",
    "        self.expected_regret = []\n",
    "        \n",
    "    def step(self, arm, render=False):\n",
    "        # pull desired arm\n",
    "        reward = np.random.binomial(1, self.p_success[arm])\n",
    "        \n",
    "        ## store info \n",
    "        self.reward_history[arm][0] += 1\n",
    "        self.reward_history[arm][1] += reward\n",
    "        self.rewards.append(reward)\n",
    "        self.expected_regret.append(self.p_max - reward)\n",
    "        \n",
    "        return reward\n",
    "   \n",
    "        \n",
    "    def render(self, show_mean=True, show_dist=True, show_actual_p=True):\n",
    "        ## plots P(p_success|n,k) for each arm      \n",
    "        \n",
    "        with self.output:\n",
    "            fig, axs = plt.subplots(self.n_arms, 1, sharex=True, figsize=(10, 10))\n",
    "            \n",
    "            for i_arm in range(self.n_arms):\n",
    "                ax = axs[i_arm] \n",
    "                # plot expected distribution of p_success.\n",
    "                # This is a beta distribution with alpha=k+1, beta=n-k+1\n",
    "                n, k = self.reward_history[i_arm]\n",
    "                \n",
    "                # plot\n",
    "                if show_actual_p:\n",
    "                    actual_p = self.p_success[i_arm]\n",
    "                    ax.axvline(actual_p, c='k', ls='--', label='Actual $p_{success}$')\n",
    "                if show_dist:\n",
    "                    #pdf\n",
    "                    p_scan = np.linspace(0,1,101)\n",
    "                    p_pdf = beta.pdf(p_scan, k + 1,n - k + 1)\n",
    "                    # ucb.\n",
    "                    p_cdf = beta.cdf(p_scan, k + 1,n - k + 1)\n",
    "                    ucb_index = np.argmin(abs(p_cdf - 0.95))\n",
    "                    ucb = p_scan[ucb_index]\n",
    "                    # plot\n",
    "                    ax.plot(p_scan, p_pdf, c='r', label='$P(p_{success}|n,k)$')\n",
    "                    ax.axvline(ucb, c='r', ls=':', label='95% UCB')            \n",
    "                if show_mean:\n",
    "                    if n != 0:\n",
    "                        mean_reward = k/n\n",
    "                    else:\n",
    "                        mean_reward = 0.5\n",
    "                    ax.axvline(mean_reward, c='b', ls='--', label='Mean reward')  \n",
    "                \n",
    "                # make pretty\n",
    "                ax.axes.set_yticks([])\n",
    "                ax.set_ylabel(\"Arm \" + str(i_arm+1))\n",
    "                ax.set_xlim([-0.05,1.05])\n",
    "                info_string = \"n = \" + str(n) + \"\\n\" + \"k = \" + str(k)\n",
    "                anchored_text = AnchoredText(info_string, loc=2)\n",
    "                ax.add_artist(anchored_text)\n",
    "        \n",
    "        \n",
    "            axs[0].set_title(\"Results\")\n",
    "            axs[-1].set_xlabel(\"$p_{success}$\")\n",
    "            \n",
    "            # add legend to lowest probability arm so there is space on right of plot\n",
    "            axs[self.arg_min].legend(loc='upper right')\n",
    "\n",
    "            # clear any output from previous call\n",
    "            clear_output(wait=True)\n",
    "            plt.show(fig)\n",
    "\n",
    "\n",
    "## Agents\n",
    "    \n",
    "class RandomAgent():\n",
    "    \"\"\"This agent chooses an arm at random\"\"\"\n",
    "    def __init__(self, env):\n",
    "        self.n_arms = env.n_arms\n",
    "        \n",
    "    def choose_arm(self):\n",
    "        choice = np.random.randint(0, self.n_arms)\n",
    "        return choice\n",
    "    \n",
    "    \n",
    "class OmniscientAgent():\n",
    "    \"\"\"This agent only pulls the best arm - not possible in reality\"\"\"\n",
    "    def __init__(self, env):\n",
    "        self.env = env\n",
    "        \n",
    "    def choose_arm(self):\n",
    "        # This agent is cheating by looking at the p_success values for each arm\n",
    "        self.best_arm = np.argmax(self.env.p_success)\n",
    "        choice = self.best_arm\n",
    "        return choice\n",
    "    \n",
    "    \n",
    "class EpsilonGreedyAgent():\n",
    "    \"\"\"This agent pulls the arm with the best mean reward so far.\n",
    "        Except with probability epsilon it pulls a random arm to aid exploration.\"\"\"\n",
    "    def __init__(self, env, epsilon=0.05):\n",
    "        self.n_arms = env.n_arms\n",
    "        self.epsilon = epsilon\n",
    "        self.env = env\n",
    "        \n",
    "    def choose_arm(self):\n",
    "        ## Mean reward for each arm is k/n\n",
    "        \n",
    "        ## Must play each arm once before comparing\n",
    "        for arm in range(self.n_arms):\n",
    "            n = self.env.reward_history[arm][0]\n",
    "            if n == 0:\n",
    "                choice = arm\n",
    "                return choice\n",
    "        \n",
    "        mean_rewards = [k/n for [n,k] in self.env.reward_history]\n",
    "        \n",
    "        random_number = np.random.random()\n",
    "        if random_number < (1 - self.epsilon):\n",
    "            # Most of the time choose arm with largest expected p_success\n",
    "            choice = np.argmax(mean_rewards)\n",
    "        else: \n",
    "            choice = np.random.randint(0, self.n_arms)\n",
    "        \n",
    "        return choice\n",
    "    \n",
    "    \n",
    "class UCBAgent():\n",
    "    \"\"\"This agent models the probaility distribution of p_success of each arm given the data so far.\n",
    "        i.e P(p_success|n,k). It then chooses the arm with the higher upper confidence bound (ucb).\"\"\"\n",
    "    def __init__(self, env, epsilon=0.05):\n",
    "        self.n_arms = env.n_arms\n",
    "        self.env = env        \n",
    "        \n",
    "    def choose_arm(self):\n",
    "        ## Model p_success with Beta distribution.\n",
    "        \n",
    "        ## Must play each arm once before comparing\n",
    "        for arm in range(self.n_arms):\n",
    "            n = self.env.reward_history[arm][0]\n",
    "            if n == 0:\n",
    "                choice = arm\n",
    "                return choice\n",
    "            \n",
    "        # Choose arm with highest 95% upper confidence limit\n",
    "        p_scan = np.linspace(0,1,101)\n",
    "        beta_ucbs = np.zeros(self.n_arms)\n",
    "        for arm in range(self.n_arms):\n",
    "            n, k = self.env.reward_history[arm]\n",
    "            # calculate ucb numerically with cumulative distribution function (cdf).\n",
    "            p_cdf = beta.cdf(p_scan, k + 1,n - k + 1)\n",
    "            ucb_index = np.argmin(abs(p_cdf - 0.95))\n",
    "            ucb = p_scan[ucb_index]\n",
    "            beta_ucbs[arm] = ucb\n",
    "        \n",
    "        choice = np.argmax(beta_ucbs)\n",
    "    \n",
    "        return choice\n",
    "    \n",
    "    \n",
    "class HumanAgent():\n",
    "    \"\"\"This allows a user to play the MAB via widget buttons.\"\"\"\n",
    "    def __init__(self, env, render_options={'show_mean': False, 'show_dist': False}):\n",
    "        self.n_arms = env.n_arms\n",
    "        self.env = env\n",
    "        # widget buttons for each arm\n",
    "        self.buttons = [widgets.Button(description=str(i_arm+1)) for i_arm in range(self.n_arms)]\n",
    "        # output for win/lose display\n",
    "        output = widgets.Output(layout=widgets.Layout(height='30px')) # for feedback\n",
    "        output2 = widgets.Output(layout=widgets.Layout(height='60px')) # for running total\n",
    "        display(widgets.VBox(self.buttons + [output, output2]))\n",
    "        \n",
    "        # optionally render the info on previous arm pulls\n",
    "        self.render_options = render_options\n",
    "        if self.render_options['show_mean'] or self.render_options['show_dist']:\n",
    "            env.render(show_mean=self.render_options['show_mean'], \n",
    "                       show_dist=self.render_options['show_dist'], \n",
    "                       show_actual_p=False)\n",
    "        \n",
    "        # function called when button pushed\n",
    "        def store_choice(_, i_button):\n",
    "            reward = self.env.step(i_button)\n",
    "\n",
    "            # feedback for user\n",
    "            with output:\n",
    "                print(\"...\")\n",
    "                time.sleep(0.2)\n",
    "                clear_output()\n",
    "                if reward == 0:\n",
    "                    print(\"Not this time :(\")\n",
    "                elif reward == 1:\n",
    "                    print(\"WINNER! :)\")\n",
    "                time.sleep(1)\n",
    "                clear_output()\n",
    "            with output2:\n",
    "                print(\"Number of goes: \" + str(len(env.rewards)))\n",
    "                print(\"Total reward: \" + str(sum(env.rewards)))\n",
    "                clear_output(wait=True)\n",
    "            \n",
    "            # optionally render the info on previous arm pulls\n",
    "            if self.render_options['show_mean'] or self.render_options['show_dist']:\n",
    "                env.render(show_mean=self.render_options['show_mean'], \n",
    "                           show_dist=self.render_options['show_dist'], \n",
    "                           show_actual_p=False)\n",
    "        \n",
    "        # tell the buttons what to do when pushed\n",
    "        for i_button in range(self.n_arms):\n",
    "            button = self.buttons[i_button]\n",
    "            button.on_click(functools.partial(store_choice, i_button=i_button))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Have a go\n",
    "\n",
    "1. First of all have a go yourself. How well do you do after 20 presses?   \n",
    "2. Then try setting 'show_mean'=True to see your average reward for each arm as you go. Does this info change how you play the game?   (You'll have to rerun the cell to reset the environment)\n",
    "3. Now try setting 'show_dist'=True. This will plot the a probability distributon for $p_{success}$ with a 95% upper confidence bound. Does this change your strategy again? Did your score improve? (Remember to rerun the cell each time you want to start from zero.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc855408a4e54e3eb5c3d14775a903ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ecc92bf047348499e5c72be77d5e64d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Button(description='1', style=ButtonStyle()), Button(description='2', style=ButtonStyle()), But…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env = MABEnv(n_arms=4)\n",
    "agent = HumanAgent(env, render_options={'show_mean': True, 'show_dist': True})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hopefully you are now getting a gist for the problem, the importance of exploration vs exploitation and you may already have worked a decent strategy. \n",
    "\n",
    "## Different solutions \n",
    "\n",
    "Here we present 4 different solutions to the MAB problem and compare them. The standard way to compare MAB algorithms is to look at their _regret_ which I will explain momentarily. \n",
    "\n",
    "The first solution I will present is a cheat. This is an omniscient agent that always knows the correct arm to pull for the highest expected reward. Note that this doesn't work in real life. The regret of the omniscient agent is 0 by definition as it never made a mistake and chose a suboptimal arm. \n",
    "\n",
    "The regret for other agents then is the difference between the expected reward from the optimal arm and the expected reward from the arm we actually pulled. \n",
    "\n",
    "The 3 other agents are:\n",
    "\n",
    "1. A random agent that chooses arms at random\n",
    "\n",
    "2. An epsilon greedy agent which calculates the mean reward for each arm and chooses the arm with highest mean reward. Except with a probablity epsilon it chooses a random arm to aid exploration. \n",
    "\n",
    "3. An upper confidence bound (UCB) agent which estimates a probability distribution for $p_{success}$ for each arm and chooses the arm with the highest UCB.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43b8aefa27b24112acf1fe44ca2b7146",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Numerical experiment to measure the regret for each agent over multiple runs. \n",
    "\n",
    "agents = [OmniscientAgent, RandomAgent, EpsilonGreedyAgent, UCBAgent]\n",
    "\n",
    "n_arms = 4\n",
    "total_pulls = 200\n",
    "n_agents = len(agents)\n",
    "n_runs = 20\n",
    "\n",
    "regret_data = np.zeros((n_agents, n_runs, total_pulls))\n",
    "\n",
    "env = MABEnv(n_arms=n_arms)\n",
    "\n",
    "for i_agent in range(n_agents):\n",
    "    agent = agents[i_agent](env)\n",
    "    \n",
    "    for i_run in range(n_runs):\n",
    "        env.reset()\n",
    "    \n",
    "        for _ in range(total_pulls):\n",
    "            \n",
    "            action = agent.choose_arm()\n",
    "            reward = env.step(action)\n",
    "\n",
    "        regret_data[i_agent, i_run, :] = env.expected_regret\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the average regret for each agent\n",
    "\n",
    "colors = ['b', 'k', 'r', 'cyan']\n",
    "\n",
    "x = range(total_pulls)\n",
    "mean_regret = regret_data.mean(axis=1)\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "for i_agent in range(n_agents):\n",
    "    y = np.cumsum(mean_regret[i_agent,:])\n",
    "    plt.plot(x, y, c=colors[i_agent], label=str(agents[i_agent].__name__))\n",
    "plt.legend();\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we see that the UCB agent performs best. (Except for the cheater omniscient agent - Note the omniscient agent regret is not exactly zero as it has been simulated through random trials.)\n",
    "\n",
    "If you want to see how the UCB agent makes its choices turn by turn then run this next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8213c90123234a76a5d438828840fd71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## test render\n",
    "\n",
    "n_arms = 3\n",
    "total_pulls = 20\n",
    "env = MABEnv(n_arms=n_arms)\n",
    "agent = UCBAgent(env)\n",
    "\n",
    "\n",
    "for _ in range(total_pulls):\n",
    "    action = agent.choose_arm()\n",
    "    reward = env.step(action)\n",
    "    env.render()    \n",
    "    time.sleep(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Here I have explained the multi-armed bandit problem and a few of the known solutions. This problem teaches us a lot about the exploration-exploitation trade off and is applicable to many real-world situations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mab_env",
   "language": "python",
   "name": "mab_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
